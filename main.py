import feedparser
import datetime
import re
import trafilatura # newspaper3k ëŒ€ì‹  ì‚¬ìš© (ë” ê°•ë ¥í•œ ë³¸ë¬¸ ì¶”ì¶œê¸°)

def get_clean_summary(url):
    """
    trafilaturaë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.
    """
    try:
        # 1. trafilaturaë¡œ ë‹¤ìš´ë¡œë“œ ë° ë³¸ë¬¸ ì¶”ì¶œ
        downloaded = trafilatura.fetch_url(url)
        
        if downloaded is None:
            return ""

        # include_comments=Falseë¡œ ëŒ“ê¸€/ê´‘ê³  ì œê±°, formatting=Trueë¡œ êµ¬ì¡° ìœ ì§€
        text = trafilatura.extract(downloaded, include_comments=False, include_tables=False, no_fallback=False)
        
        if not text or len(text) < 50:
            return ""

        # 2. í…ìŠ¤íŠ¸ ì •ì œ (ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ)
        text = text.replace('\n', ' ').strip()
        text = re.sub(r'\s+', ' ', text)

        # 3. ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬ (ê°„ì´ ë¡œì§)
        sentences = text.split('. ')
        
        summary_sentences = []
        char_count = 0
        
        for sent in sentences:
            clean_sent = sent.strip()
            if not clean_sent: continue
            
            # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥(ê¸°ì ì´ë©”ì¼, í¬í† ë‰´ìŠ¤ ì„¤ëª… ë“±) ê±´ë„ˆë›°ê¸°
            if len(clean_sent) < 20: continue
            
            # ë¬¸ì¥ ë ë§ˆì¹¨í‘œ ë³´ì •
            if not clean_sent.endswith('.'):
                clean_sent += '.'
            
            summary_sentences.append(clean_sent)
            char_count += len(clean_sent)
            
            # ì•½ 350ì ë‚´ì™¸ì—ì„œ ëŠê¸°
            if char_count > 350:
                break
        
        # ë¬¸ì¥ì´ ë„ˆë¬´ ì ìœ¼ë©´(1ë¬¸ì¥ ë¯¸ë§Œ) ìš”ì•½ ì‹¤íŒ¨ë¡œ ê°„ì£¼
        if not summary_sentences:
            return ""

        return ' '.join(summary_sentences)

    except Exception as e:
        # ë¡œê·¸ì— ì—ëŸ¬ë¥¼ ë‚¨ê²¨ ë””ë²„ê¹… ìš©ì´í•˜ê²Œ í•¨
        print(f"[Error] Failed to summarize {url}: {e}")
        return ""

def fetch_news():
    # RSS ì†ŒìŠ¤ ìµœì í™”
    sources = {
        "ğŸ¤– ì¸ê³µì§€ëŠ¥ (AI)": "http://www.aitimes.com/rss/allArticle.xml",
        # ë§¤ì¼ê²½ì œ ì¢…í•© ëŒ€ì‹  'í•œêµ­ê²½ì œ(í•œê²½) ê²½ì œ ì„¹ì…˜'ìœ¼ë¡œ ë³€ê²½ (ë‚ ì”¨/ì—°ì˜ˆ ë°°ì œ)
        "ğŸ’° ê²½ì œ": "https://www.hankyung.com/feed/economy", 
        # ë™ì•„ì¼ë³´ êµìœ¡ ì„¹ì…˜ (trafilaturaë¡œ ì¶”ì¶œ ì‹œë„)
        "ğŸ“ êµìœ¡": "https://rss.donga.com/education.php" 
    }
    
    now = datetime.datetime.now()
    today_str = now.strftime("%Y-%m-%d")
    update_time = now.strftime("%Y-%m-%d %H:%M:%S")
    
    markdown = f"""---
date: {today_str}
last_update: {update_time}
type: insight
topic: [ì¸ê³µì§€ëŠ¥, ê²½ì œ, êµìœ¡]
tags: [ë‰´ìŠ¤, ìš”ì•½, {today_str}]
source: [AIíƒ€ì„ìŠ¤, í•œêµ­ê²½ì œ, ë™ì•„ì¼ë³´]
---

# ğŸ“… {now.strftime('%Yë…„ %mì›” %dì¼(%a)')} í•µì‹¬ ë‰´ìŠ¤ ë¸Œë¦¬í•‘

"""
    
    first_title = "" 

    for category, rss_url in sources.items():
        markdown += f"## {category}\n"
        print(f"Processing Category: {category}...") # ì§„í–‰ìƒí™© ì¶œë ¥
        
        try:
            feed = feedparser.parse(rss_url)
            success_count = 0
            
            for entry in feed.entries:
                if success_count >= 2: break
                
                print(f" - Trying: {entry.title}") # ì–´ë–¤ ê¸°ì‚¬ë¥¼ ì‹œë„í•˜ëŠ”ì§€ ì¶œë ¥
                summary = get_clean_summary(entry.link)
                
                if not summary:
                    print("   -> Fail (Content empty or too short)")
                    continue
                
                print("   -> Success!")
                markdown += f"### ğŸ”— [{entry.title}]({entry.link})\n"
                markdown += f"> {summary}\n\n"
                
                # íŒŒì¼ëª… ìƒì„±ì„ ìœ„í•œ ì²« ë²ˆì§¸ ê¸°ì‚¬ ì œëª© ì¶”ì¶œ
                if not first_title:
                    clean_title = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', entry.title).strip()
                    first_title = clean_title.replace(" ", "_")[:15]
                
                success_count += 1
                
        except Exception as e:
            print(f"Error in category {category}: {e}")

    markdown += "---\n"
    markdown += f"### ğŸ“‚ ìë™í™” ê¸°ë¡ ì•ˆë‚´\n"
    markdown += f"ìµœì¢… ì—…ë°ì´íŠ¸ ì‹œê°: **{update_time}**\n"
    
    # ì œëª©ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ê°’
    if not first_title:
        first_title = "News_Briefing"

    filename = f"{today_str}_{first_title}.md"
    return filename, markdown

if __name__ == "__main__":
    filename, content = fetch_news()
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"Created: {filename}")
