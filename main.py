def fetch_news():
    # ë¶„ì•¼ë³„ë¡œ ì‹ ë¢°ë„ ë†’ì€ ì„œë¡œ ë‹¤ë¥¸ ì–¸ë¡ ì‚¬ RSSë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
    feeds = {
        "ì¸ê³µì§€ëŠ¥(AI)": "http://www.aitimes.com/rss/allArticle.xml", # AI ì „ë¬¸ì§€
        "êµìœ¡": "https://www.edunews.co.kr/rss/allArticle.xml",     # êµìœ¡ ì „ë¬¸ì§€
        "ì •ì¹˜/ì‚¬íšŒ": "https://www.yna.co.kr/rss/news.xml"           # ì—°í•©ë‰´ìŠ¤ ì†ë³´
    }
    
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    today_with_day = datetime.datetime.now().strftime("%Y-%m-%d(%a)")
    
    content = f"""---
date: {today_str}
type: insight
tags: [AI, êµìœ¡, ì •ì¹˜, ì‚¬íšŒ]
---

# ğŸ“… {today_with_day} ë¶„ì•¼ë³„ ì¢…í•© ë‰´ìŠ¤ ë¸Œë¦¬í•‘

"""

    brief_summary = ""

    for category, url in feeds.items():
        feed = feedparser.parse(url)
        # í”¼ë“œ ì—°ê²° ì‹¤íŒ¨ ì‹œ ê±´ë„ˆë›°ê¸°
        if not feed.entries:
            continue
            
        content += f"## ğŸ“Œ {category} ë¶„ì•¼\n"
        
        for i, entry in enumerate(feed.entries[:3]):
            # HTML íƒœê·¸ ì œê±°
            summary = re.sub('<[^<]+?>', '', entry.description) if 'description' in entry else "ë‚´ìš©ì€ ë§í¬ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
            # ìš”ì•½ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            summary = summary.strip()[:150] + "..." if len(summary) > 150 else summary
            
            content += f"### {entry.title}\n"
            content += f"- **í•µì‹¬ë‚´ìš©:** {summary}\n"
            content += f"- [ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°]({entry.link})\n\n"
            
            # íŒŒì¼ ì œëª©ìš© ìš”ì•½ (ì²« ë²ˆì§¸ ë¶„ì•¼ì˜ ì²« ë²ˆì§¸ ê¸°ì‚¬ ì œëª©)
            if not brief_summary:
                brief_summary = re.sub(r'[\\/:*?"<>|]', '', entry.title)[:20]

    filename = f"{today_str} {brief_summary}.md"
    return filename, content
