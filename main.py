import feedparser
import datetime
from datetime import timedelta, timezone
import re
import trafilatura
import os

# ---------------------------------------------------------
# 1. í•œêµ­ ì‹œê°„(KST) ì„¤ì • (GitHub ì„œë²„ ì‹œê°„ ë³´ì •ìš©)
# ---------------------------------------------------------
KST = timezone(timedelta(hours=9))

def get_korea_time():
    """í˜„ì¬ í•œêµ­ ì‹œê°„ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    return datetime.datetime.now(KST)

# ---------------------------------------------------------
# 2. ë‰´ìŠ¤ ë³¸ë¬¸ ì¶”ì¶œ ë° ì •ì œ í•¨ìˆ˜ (Trafilatura í™œìš©)
# ---------------------------------------------------------
def get_clean_summary(url):
    try:
        # ë³¸ë¬¸ ë‹¤ìš´ë¡œë“œ (User-Agent ìë™ ìœ„ì¥ìœ¼ë¡œ ì°¨ë‹¨ ë°©ì§€)
        downloaded = trafilatura.fetch_url(url)
        
        if downloaded is None:
            return None

        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)
        
        if not text or len(text) < 50:
            return None

        # í…ìŠ¤íŠ¸ ì •ì œ (ë¶ˆí•„ìš”í•œ ê³µë°± ë° ì¤„ë°”ê¿ˆ ì œê±°)
        text = text.replace('\n', ' ').strip()
        text = re.sub(r'\s+', ' ', text)

        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ ìš”ì•½ ìƒì„± (ìµœëŒ€ 300ì)
        sentences = text.split('. ')
        summary_sentences = []
        char_count = 0
        
        for sent in sentences:
            clean_sent = sent.strip()
            if len(clean_sent) < 20: continue # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸
            
            if not clean_sent.endswith('.'):
                clean_sent += '.'
            
            summary_sentences.append(clean_sent)
            char_count += len(clean_sent)
            
            if char_count > 350: # ìš”ì•½ ê¸¸ì´ ì œí•œ (ì•½ 3~4ë¬¸ì¥)
                break
        
        return ' '.join(summary_sentences) if summary_sentences else None

    except Exception as e:
        print(f"âš ï¸ ìš”ì•½ ì‹¤íŒ¨ ({url}): {e}")
        return None

# ---------------------------------------------------------
# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë§ˆí¬ë‹¤ìš´ ìƒì„± ë©”ì¸ í•¨ìˆ˜
# ---------------------------------------------------------
def fetch_news():
    # ì‹ ë¢°ë„ ë†’ì€ ë‰´ìŠ¤ ì†ŒìŠ¤ ëª©ë¡ (í•„ìš”ì‹œ ìˆ˜ì • ê°€ëŠ¥)
    sources = {
        "ğŸ¤– ì¸ê³µì§€ëŠ¥ (AI)": "http://www.aitimes.com/rss/allArticle.xml",
        "ğŸ’° ê²½ì œ": "https://www.hankyung.com/feed/economy", 
        "ğŸ“ êµìœ¡": "http://www.veritas-a.com/rss/allArticle.xml" 
    }
    
    now = get_korea_time()
    today_str = now.strftime("%Y-%m-%d")
    
    # ì˜¤ì „/ì˜¤í›„ êµ¬ë¶„ ë¡œì§
    time_tag = "ì˜¤ì „" if now.hour < 12 else "ì˜¤í›„"
    
    # ì˜µì‹œë””ì–¸ìš© Frontmatter ì‘ì„±
    markdown = f"""---
date: {today_str}
time: {now.strftime("%H:%M:%S")}
type: news_briefing
tags: [ë‰´ìŠ¤, {time_tag}, ìë™í™”]
created_at: {now.strftime("%Y-%m-%d %H:%M:%S")}
---

# ğŸ“… {now.strftime('%Yë…„ %mì›” %dì¼')} {time_tag} ë‰´ìŠ¤ ë¸Œë¦¬í•‘

"""
    
    # ê° ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘
    for category, rss_url in sources.items():
        markdown += f"## {category}\n"
        print(f"ğŸ” [{category}] ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        
        try:
            feed = feedparser.parse(rss_url)
            success_count = 0
            
            for entry in feed.entries:
                if success_count >= 3: break # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 3ê°œ ê¸°ì‚¬ë§Œ
                
                print(f"  - ë¶„ì„ ì¤‘: {entry.title}...")
                
                # ë³¸ë¬¸ ìš”ì•½ ì‹œë„
                summary = get_clean_summary(entry.link)
                
                # ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ RSS ê¸°ë³¸ ìš”ì•½(description) ì‚¬ìš©
                if not summary:
                    summary = entry.get('description', '')[:100] + "..." if 'description' in entry else "ìš”ì•½ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    summary = re.sub(r'<[^>]+>', '', summary) # HTML íƒœê·¸ ì œê±°
                
                # ë§ˆí¬ë‹¤ìš´ì— ì¶”ê°€
                markdown += f"### ğŸ”— [{entry.title}]({entry.link})\n"
                markdown += f"> {summary}\n\n"
                success_count += 1
                
        except Exception as e:
            markdown += f"> âš ï¸ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\n\n"

    markdown += "---\n"
    markdown += f"âœ… **ìµœì¢… ì—…ë°ì´íŠ¸(í•œêµ­ì‹œê°„):** {now.strftime('%Y-%m-%d %H:%M:%S')}\n"

    # íŒŒì¼ëª… ìƒì„± (ì˜ˆ: 2026-01-27_ì˜¤í›„_Daily_News.md)
    # êµ¬ì²´ì ì¸ ì‹œê°„(ì‹œ/ë¶„)ì„ ì›í•˜ì‹œë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‚¬ìš©í•˜ì„¸ìš”
    # filename = f"{today_str}_{time_tag}_{now.strftime('%Iì‹œ_%Më¶„')}_News.md"
    filename = f"{today_str}_{time_tag}_Daily_News_Briefing.md"
    
    return filename, markdown

# ---------------------------------------------------------
# 4. ì‹¤í–‰ ë° íŒŒì¼ ì €ì¥
# ---------------------------------------------------------
if __name__ == "__main__":
    filename, content = fetch_news()
    
    # GitHub Actions í™˜ê²½ì—ì„œ ì‹¤í–‰ë  ë•Œ íŒŒì¼ ì €ì¥
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
        
    print(f"\nğŸ‰ íŒŒì¼ ìƒì„± ì™„ë£Œ: {filename}")
